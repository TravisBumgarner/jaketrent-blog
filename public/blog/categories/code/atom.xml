<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Code | Jake Trent]]></title>
  <link href="http://jaketrent.com/blog/categories/code/atom.xml" rel="self"/>
  <link href="http://jaketrent.com/"/>
  <updated>2017-01-24T07:53:25-07:00</updated>
  <id>http://jaketrent.com/</id>
  <author>
    <name><![CDATA[Jake Trent]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Deploy create-react-app to Heroku on Node.js]]></title>
    <link href="http://jaketrent.com/post/deploy-create-react-app-heroku-node/"/>
    <updated>2017-01-19T07:48:00-07:00</updated>
    <id>http://jaketrent.com/post/deploy-create-react-app-heroku-node</id>
    <content type="html"><![CDATA[<p>Create-react-app is Facebook's no-config solution to starting a React project.  This setup does not support a server out of the box.  You can create that easily enough.  Node.js can be a good choice for your app server.  Once it's made and functioning, you might want to deploy your static app and app server.  Here's a few tips on getting them up onto Heroku.</p>

<p><img src="http://i.imgur.com/6DUwRKt.png" alt="Create-react-app on Heroku" /></p>

<!--more-->


<h2>Two Builds</h2>

<p>Create-react-app comes with two npm-scripts targets.  One is the live dev server that builds assets in a development configuration and serves them out of webpack-dev-server.  This is run with <code>npm start</code>.  When you're ready for prod, however, there is a <code>npm run build</code> script that will build all assets for a production setting.  In this configuration, it's up to you to provide the server to serve such assets.</p>

<h2>Serving Static Assets on Koa</h2>

<p>Koa is a nice web framework for Node.js that is fun to write little app servers in.  If you want to tack on web server abilities like serving static assets, that's easy to do as well.</p>

<p>Assuming that you have the basics of your koa server already going, you now want to:</p>

<p><code>
npm install koa-static --static
</code></p>

<p>Now you need to use the static middleware.  The main thing you need to know in order to use it is the location of your static assets.  When you previously ran <code>npm run build</code>, create-react-app puts the built files into a <code>build/</code> directory in the root of your project.  You want to point the middleware there:</p>

<p>```js
const koa = require('koa')
const path = require('path')
const static = require('koa-static')</p>

<p>const app = koa()
app.use(static(path.resolve('build')))
// ...
```</p>

<p>Now requests for static files that your app might make will route to that <code>build/</code> directory.  For instance, your main js bundle, probably called something like <code>/static/js/main.f682b6a1.js</code> will be addressable because of this middleware.</p>

<p>It's important to note that the assets in the <code>build/</code> directory will only exists (or be updated) when <code>npm run build</code> is run.  The directory does <em>not</em> contain the live-updated assets that you might be used to seeing in your development cycle of changing a file, refreshing your browser, and getting the change.</p>

<h2>Serving Your React App</h2>

<p>Since you've decided to serve all static assets via your app server, this includes the <code>index.html</code> which will bootstrap your React app.  Create-react-app is setup to build this file as well, depositing it at <code>build/index.html</code>.  You'll want a route in your app server that can serve this as the html that will request the other js and css static assets needed to get your React program fired up.</p>

<p>Koa has a nice helper for establishing route patterns.  Let's grab that:</p>

<p><code>
npm install koa-route --save
</code></p>

<p>And then setup our index route:</p>

<p>```js
const fs = require('fs')
const route = require('koa-route')</p>

<p>function* index() {
  this.body = fs.readFileSync(path.resolve(path.join('build', 'index.html')), 'utf8')
}</p>

<p>app.use(route.get('*', index))
```</p>

<p>The reason to map the index route to <code>*</code> instead of <code>/</code> is because your React app likely has <em>client</em>-side routes.  So if the client-side router has an <code>/about</code> route to the about page, you'll want a user to be able to deep link straight to that experience: the user refreshes the page, makes a request to your koa server at your domain, it doesn't have a server route for <code>/about</code>, but drops to the <code>*</code> route handler, serves the <code>index.html</code>, which invokes your React app, starting the client router, which has a route for <code>/about</code> and serves that UI via React.</p>

<h2>Build When Deploying</h2>

<p>Now that you have an app that is served successfully from a koa server locally, you want to get that on Heroku.  That's one of the best things about Heroku: the ease with which you can put your app on the Internet.  Now you just need to get the deployment to automatically do what you did locally.</p>

<p>After you pushed your app to Heroku, you could manually run:</p>

<p><code>
heroku run npm run build
</code></p>

<p>Then your static assets would be in the expected spot.  But you don't want to have to remember to do this every deploy.  Thankfully, Heroku gives you a nice hook to automatically do things after you run a deploy.</p>

<p>In your <code>package.json</code> file, add a new script:</p>

<p>```json package.json
{
  "scripts": {</p>

<pre><code>"heroku-postbuild": "npm run build"
</code></pre>

<p>  }
}
```</p>

<p>Commit and push this to Heroku, and you'll get your assets building automatically on every deploy.  Create-react-app with a Node.js server on Heroku will be yours!</p>

<p>Are there better or simpler ways that you've found to get this done?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DateTime in F#]]></title>
    <link href="http://jaketrent.com/post/datetime-in-fsharp/"/>
    <updated>2017-01-04T11:11:00-07:00</updated>
    <id>http://jaketrent.com/post/datetime-in-fsharp</id>
    <content type="html"><![CDATA[<p>I've said jokingly, when coding through date/time-related problems, someone could do a PhD on this stuff.  Surely they have.  It can get complicated.  Here are a few core facts related to Utc time and the usage of .Net's <code>System.DateTime</code> and <code>System.DateTimeOffset</code> classes that you may find useful.</p>

<p><img src="http://i.imgur.com/L5olAv0.png" alt="f#" /></p>

<!--more-->


<h2>Universal vs. Local Time</h2>

<p>Utc is universal time.  All hosts in the world can store a time in Utc and make comparisons between one another.  If your company had two hosts, one in Oregon and one in Hong Kong, and they did an operation at the exact same time, that time would be stored as the exact same value in Utc, or universal, time.  But the time value would be different locally, because there is a 16-hour time difference between what the local clock reads in Oregon vs Hong Kong at the moment of that operation.  If you want to make time comparisons or calculations or have interop between systems in different geographies, always use Utc time.</p>

<h2>System.DateTime</h2>

<p>In .Net, <code>System.DateTime</code> can represent many things.  It might be a local time construct or a Utc time or neither.  This is determined by its <a href="https://msdn.microsoft.com/en-us/library/shx7s921(v=vs.110).aspx"><code>System.DateTimeKind</code> member</a>.  When instantiated, <code>System.DateTime</code> is of kind <code>DateTimeKind.Unspecified</code>.  You must add an additional line of code, assigning the <code>DateTimeKind</code> using the static method of <code>DateTime.SpecifyKind</code>.  Using the <code>DateTimeKind</code>, you can make a <code>DateTime</code> Utc.</p>

<h2>System.DateTimeOffset</h2>

<p>In .Net, <code>System.DateTimeOffset</code> is a wrapper around a local <code>DateTime</code> and a <code>TimeSpan</code> offset from universal time.  (As a side note, the "Utc offset" is not the same as a time zone, even though the values might match up.  Time zone is a totally different construct with surrounding history and customs.)  The reason that it is a time <em>with</em> an offset is so that the original local time of the observer of the time (eg, Hong Kong host) can be stored <em>with</em> the offset from Utc at that moment, which allows it to represent a universal time as well.  Thus, <code>DateTimeOffset</code> can store <em>more</em> information: the local time and the offset that allows conversion to Utc time.</p>

<p>Interestingly, however, one can erase this local time storage by using <code>System.DateTimeOffset.UtcNow</code> when trying to instantiate an object that is "the current time".  The current time that will be stored is the Universal time or the time in Greenwich, England (offset of +00:00).  You lose the local time storage.  <code>System.DateTimeOffset</code> can give you the best of both worlds if you store "the current time" using <code>System.DateTimeOffset.Now</code>, keeping a local time and also the offset to Utc, allowing easy conversion to universal time.</p>

<h2>Which is Best?</h2>

<p>Which one you should use isn't as clear.</p>

<p><code>DateTime</code> requires 2 steps before it's clear what time it is.  This can require discipline that we might not want to give to our developers.</p>

<p><code>DateTimeOffset</code> infers a knowledge about Utc, because it includes an offset to Utc.  Thus Utc can always be determined from this object.  But transport of the <code>DateTimeOffset</code> to another system, such as a database, might not store the offset, effectively stripping it.  Before it was stripped, did you convert to Utc or is it still local time?  And after you query the data, how do you know what time it is?  So you might like the combo of <code>Sytem.DateTimeOffset</code> knowing about local time <em>and</em> the offset, but the potentially of handling this data in translation might make you think twice.</p>

<p>It does seem clear that it's easy to become unclear about what your dates mean.  Organizations, especially those with multiple systems that need to interop with dates and times, need to put forth effort to be clear about how they'll approach this.  Interoperating systems to need to handle dates and times consistently.  This should be written down and documented.  Guides for your approach should be shared for your tech stacks.</p>

<p>What date/time objects do you use and why?  How do you keep these straight between your systems?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debug.log in Elm Pipes]]></title>
    <link href="http://jaketrent.com/post/debug-log-in-elm-pipes/"/>
    <updated>2016-12-15T09:32:00-07:00</updated>
    <id>http://jaketrent.com/post/debug-log-in-elm-pipes</id>
    <content type="html"><![CDATA[<p>There aren't many functions in the standard lib for elm that create side effects.  Elm's <code>Debug.log</code> is one of those exceptions.  It logs to the console.  Here's how it's setup to make console logging whilst piping easier that patting your head whilst rubbing your tummy.</p>

<p><img src="http://i.imgur.com/1c6FH0f.png" alt="elm debug.log" /></p>

<!--more-->


<h2>The signature of Debug.log</h2>

<p>The coolest thing about <code>Debug.log</code> is its type signature:</p>

<p><code>
String -&gt; a -&gt; a
</code></p>

<p>The first parameter is <code>String</code> and traditionally takes some label to identify what you're printing in the log.</p>

<p>The 2nd parameter is <code>a</code>, meaning it can be generically anything.   It's worth noticing that <code>a</code> as the 2nd parameter is required.  This means you'll have to print a value there whether you want to or not.  Otherwise, you won't be fully applying the <code>Debug.log</code> function.</p>

<p>The <em>coolest</em> part is that <code>a</code> is also returned.  This helps with piping because you can just insert <code>Debug.log</code> in your pipe chain.</p>

<h2>Logging in Elm</h2>

<p>Here's a little example.  In this <code>encode</code> function there are several pipes.  There are two helper functions, <code>keyIndex</code> and <code>keyValue</code> that return values that I'd like to investigate.  After each of those values are returned in the pipe chain, a <code>Debug.log</code> is inserted next in the chain with the associated "indexes" or "values" label for log clarity.</p>

<p>```haskell
encode : String -> String
encode phrase =</p>

<pre><code>phrase
    |&gt; String.toLower
    |&gt; String.split ""
    |&gt; List.map (\l -&gt; l |&gt; keyIndex)
    |&gt; Debug.log "indexes"
    |&gt; List.map (\i -&gt; -1 * i)
    |&gt; List.map keyValue
    |&gt; Debug.log "values"
    |&gt; String.join ""
</code></pre>

<p>```</p>

<p>The resulting log for a test run of this code is:</p>

<p><code>
indexes: [24,4,18]
values: ["b","v","h"]
</code></p>

<p>This can be super nice when you're not in a live debug-ready environment.  What are some other ways to gain insight into your code for debugging that you use?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Stub Dependencies in Node Without Proxyquire]]></title>
    <link href="http://jaketrent.com/post/stub-dependencies-node-without-proxyquire/"/>
    <updated>2016-09-29T06:30:00-06:00</updated>
    <id>http://jaketrent.com/post/stub-dependencies-node-without-proxyquire</id>
    <content type="html"><![CDATA[<p>When testing a unit, often you'll want to stub out that unit's dependencies.  Some libraries will help you do this.  But you can do it with plain JavaScript, and it works quite well.</p>

<p><img src="http://i.imgur.com/1arT8Ho.jpg" alt="nodejs testing" /></p>

<!--more-->


<h2>Stubbing Dependencies</h2>

<p>We're unit testing a module in Node.  That unit has dependencies on some other sub-unit.  For our example, these units are modules. The subject under test is <code>prep-for-fight.js</code>.  It has a dependency on <code>eat-corn.js</code>.  We want to eventually stub out <code>eat-corn.js</code> within our unit test for <code>prep-for-fight.js</code>.</p>

<p>```js prep-for-fight.js
const eatCorn = require('./eat-corn')
module.exports = function prepForFight() {
  const nutrients = eatCorn()
  if (nutrients > NUTRIENT_LEVELS.EAGLE_EMPOWERMENT)</p>

<pre><code>return { hasCape: donHomemadeCape() }
</code></pre>

<p>  // ...
}
```</p>

<p>A <a href="/post/sinon-spies-vs-stubs/">stub</a> is a testing fake that you create in place of the real thing.  While testing our module <code>prepForFight</code>, we'll stub out the sub-unit module <code>eatCorn</code>.  That module is tested elsewhere in another unit test.  We don't want to conflate the two tests, coupling them strongly together.  This is because if the sub-unit's implementation changes, we don't want to have to change our current unit's test.</p>

<p>The tradeoff is that we are going to couple our <code>prepForFight</code> unit test to the implementation of that module.  This is generally known as white box testing, where we care about the internal implementation of our source code within our tests.  If we did the opposite, and treated <code>prepForFight</code> as a black box and just tested its final output, there really is no need to stub anything or ever care about implementation as long as <code>prepForFight</code> continues to do its job.  For today's example, we'll choose to stub so that we can have a more isolated unit and focused test, drawing our unit boundaries strictly around code that exists in <code>prepForFight</code> proper.</p>

<h2>Stubbing Libraries</h2>

<p>There are libraries that help us stub.  Since we have a <code>require</code>d module for <code>eat-corn.js</code>, there is one in particular that would do well for us called <a href="https://github.com/thlorenz/proxyquire">proxyquire</a>.  It allows targeting the <code>./eat-corn.js</code> import path and replacing it with your own module at test runtime.  With a couple caveats, it usually works quite well.  We're going to <em>not</em> use it and see how we fare.</p>

<h2>Stub by Passing the Dependency</h2>

<p>An easy way to get a dependency into <code>prepForFight</code> is to pass it as a function argument.  The rewrite might look like this:</p>

<p>```js prep-for-fight.js
module.exports = function prepForFight(eatCorn) {
  const nutrients = eatCorn()
  if (nutrients > NUTRIENT_LEVELS.EAGLE_EMPOWERMENT)</p>

<pre><code>return { hasCape: donHomemadeCape() }
</code></pre>

<p>  // ...
}
```</p>

<p>Now we have no <code>require</code> statement, and <code>prepForFight</code> gets the dependency it needs.  Given this implementation, we can exercise our two code paths in our test:</p>

<p>```js prep-for-fight.spec.js
const test = require('ava') // or whatevs</p>

<p>const subject = require('./prep-for-fight')</p>

<p>test('many nutrients dons cape', t => {
  function eatCornStub() {</p>

<pre><code>return NUTRIENT_LEVELS.EAGLE_EMPOWERMENT + 1
</code></pre>

<p>  }
  t.truthy(subject(eatCornStub).hasCape)
})</p>

<p>test('fewer nutrients remains cape-less', t => {
  function eatCornStub() {</p>

<pre><code>return NUTRIENT_LEVELS.EAGLE_EMPOWERMENT - 1
</code></pre>

<p>  }
  t.falsy(subject(eatCornStub).hasCape)
})
```</p>

<p>By passing in our stub directly, we control the branching inside the function.</p>

<h2>Leaking Dependencies</h2>

<p>By exposing <code>eatCorn</code> as a function parameter, we're telling all consumers that we rely on <code>eatCorn</code>.  We've leaked our dependency, lessening our encapsulation.  For the function to work as written, it always needs the consumer to send it the <code>eatCorn</code> argument when <code>prepForFight</code> is called.  Let's give it a default, and make the consumer code care about our dependencies a bit less.  The default will be our original <code>require</code>d module.</p>

<p>```js prep-for-fight.js
const defaultEatCorn = require('./eat-corn')
module.exports = function prepForFight(eatCorn = defaultEatCorn) {
  const nutrients = eatCorn()
  if (nutrients > NUTRIENT_LEVELS.EAGLE_EMPOWERMENT)</p>

<pre><code>return { hasCape: donHomemadeCape() }
</code></pre>

<p>  // ...
}
```</p>

<p>Now if <code>eatCorn</code> is <em>passed</em> as an argument, it will be used.  Otherwise, <code>defaultEatCorn</code>, which is the normal imported dependency, will be used.  This is great because now consumers don't necessarily have to care about the dependency, except to override, which for now is just a thing our test wants to be able to do.</p>

<h2>Stub Without Changing Your Signature</h2>

<p>If putting <code>eatCorn</code> in your function parameter list bothers you, here's another potential solution.</p>

<p>```js prep-for-fight.js
const eatCorn = require('./eat-corn')
exports.prepForFight = function prepForFight() {
  const nutrients = eatCorn()
  if (nutrients > NUTRIENT_LEVELS.EAGLE_EMPOWERMENT)</p>

<pre><code>return { hasCape: donHomemadeCape() }
</code></pre>

<p>  // ...
}</p>

<p>exports.withEatCornForTest = function withEatCornForTest(eatCornOverride) {
  eatCorn = eatCornOverride
}
```</p>

<p>Now you can call <code>withEatCornForTest</code> before you exercise your subject under test:</p>

<p>```js prep-for-fight.spec.js
const test = require('ava')</p>

<p>const subject = require('./prep-for-fight')</p>

<p>test('many nutrients dons cape', t => {
  function eatCornStub() {</p>

<pre><code>return NUTRIENT_LEVELS.EAGLE_EMPOWERMENT + 1
</code></pre>

<p>  }
  subject.withEatCornForTest(eatCornStub)
  t.truthy(subject.prepForFight().hasCape)
})
```</p>

<p>This overrides the imported <code>eatCorn</code> module much like proxyquire does.  This is nice because your <code>prepForFight</code> function remains untouched, but I think there are a few drawbacks.</p>

<ul>
<li>We had to change our single export module to a multiple named export module in order to add the extra API for setting the dependency.</li>
<li>We have code in our src that is there specifically for testing.  The <code>*ForTest</code> suffix is a particularly clear flag of that.  But if we remove the <code>*ForTest</code> suffix, we simply cloud that fact and make something still test-specific look like it's for general use.</li>
<li>We have made our <code>prepForFight</code> function impure, because now its output can change depending on when or if we call the <code>withEatCornForTest</code>, creating a module-global side effect.</li>
<li><code>withEatCornForTest</code> is further away from the <code>eatCorn</code> usage inside of <code>prepForFight</code>.  Thus, we could read <code>prepForFight</code> and never know that it's possible for the <code>eatCorn</code> implementation to be switched out from under us without examination of more code outside that function.</li>
</ul>


<h2>Decouple Function Parameter Order</h2>

<p>Previous to reading Sandi Metz' <a href="http://www.poodr.com/">POODR</a> book, I hadn't considered this, but she posits that a parameter list has coupling because of the order of the parameters.  To lessen the coupling, she proposes changing the function signature to take an argument hash instead.  This has the benefits of not requiring a specific order, letting consumers name the arguments, creating clarity on the consuming side, and having the consistency of a single argument for most/if not all functions that take input.</p>

<p>We can take advantage of these attributes and realize one of our own in our <code>prepForFight</code> function.  If we have multiple dependencies, we can put these dependencies and their defaults inside the argument hash, and no consumer has to know anything about it.  There's no ordering problem.  There's no null arugment passing.  We just specify the keys that we care to specify and have defaults for the rest.  A minor refactor might yield some destructuring of a single object sent to the function:</p>

<p>```js prep-for-fight.js
const defaultEatCorn = require('./eat-corn')
module.exports = function prepForFight({ eatCorn = defaultEatCorn /<em>, more... </em>/ }) {
  const nutrients = eatCorn()
  if (nutrients > NUTRIENT_LEVELS.EAGLE_EMPOWERMENT)</p>

<pre><code>return { hasCape: donHomemadeCape() }
</code></pre>

<p>  // ...
}
```</p>

<p>I think that's probably our final refactor for now.  What could we do to make this better?  What are other stubbing methods that you've gotten a lot of mileage out of?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notify NewRelic of Error on UncaughtException]]></title>
    <link href="http://jaketrent.com/post/notify-error-to-newrelic-on-uncaughtexception/"/>
    <updated>2016-09-27T09:50:00-06:00</updated>
    <id>http://jaketrent.com/post/notify-error-to-newrelic-on-uncaughtexception</id>
    <content type="html"><![CDATA[<p>NewRelic is a monitoring vendor that has good support for Node.js apps.  When your Node app goes down, you'll want to tell NewRelic about it.  It's surprisingly easy.</p>

<p><img src="http://i.imgur.com/ApNvY7f.jpg" alt="newrelic" /></p>

<!--more-->


<h2><code>newrelic</code> npm Package</h2>

<p>The <code>newrelic</code> npm package is super easy to integrate with.  First install:</p>

<p><code>
npm install newrelic
</code></p>

<p>Call it from early in your program (before errors can start to occur).  NewRelic docs say on the first line of your program.  I load config first.  Everything is fine.</p>

<p><code>js
require('newrelic')
</code></p>

<p>Then in order to let NewRelic have the data that it needs to run, you'll need to setup the config file.  The lib gives you a seed file to start from.</p>

<p><code>
cd &lt;proj_root&gt;
cp node_modules/newrelic/newrelic.js .
</code></p>

<p>Make sure to edit it with your changes.  With that file, you'll want to set your app name, your license key, and any other <a href="https://github.com/newrelic/node-newrelic/blob/master/lib/config.default.js">options you desire</a>.</p>

<h2>Calling NewRelic on <code>uncaughtException</code></h2>

<p>When your Node app goes down, you have <a href="post/handle-errors-node-app/">one final moment</a> to send out your SOS signal -- this is in the <code>uncaughtException</code> handler.</p>

<p>Usually NewRelic will detect errors automatically, such as those that you return as HTTP responses to your clients of status 500 with some error json.  But in this case, we'll need to send the error manually.  The <code>newrelic</code> lib gives us a way to do this with the <code>notifyError</code> function.  It takes the error object and optionally some custom parameters.</p>

<p>So, at first glace, we'd do this:</p>

<p>```js
const newrelic = require('newrelic')</p>

<p>process.on('uncaughtException', err => {
  log.fatal({ err }, 'unhandled error')</p>

<p>  newrelic.noticeError(err)
  process.exit(1)
})
```</p>

<p>But this doesn't deterministically give NewRelic time enough to send the error off to their server.  The lib apparently sends errors on some sort of "harvest" cadence.  <code>process.nextTick</code> doesn't seem to provide enough time either.  But NewRelic does give another API that should help.  The <code>shutdown</code> function cleans up the agent.  It also allows to flush all the pending notifications via <code>collectPendingData</code> option previous to shutdown, which is what we want.</p>

<p>So to make this reliable, we change to:</p>

<p>```js
process.on('uncaughtException', err => {
  log.fatal({ err }, 'unhandled error')</p>

<p>  newrelic.noticeError(err)
  newrelic.shutdown({ collectPendingData: true }, err => {</p>

<pre><code>if (err) log.error({ err }, 'error shutting down newrelic agent')
process.exit(1)
</code></pre>

<p>  })
})
```</p>

<p>And it works like a charm.  Any additional data that you send to monitoring when your app crashes?  Any ways that you know to make this more reliable?  Have fun logging those crashes!</p>
]]></content>
  </entry>
  
</feed>
